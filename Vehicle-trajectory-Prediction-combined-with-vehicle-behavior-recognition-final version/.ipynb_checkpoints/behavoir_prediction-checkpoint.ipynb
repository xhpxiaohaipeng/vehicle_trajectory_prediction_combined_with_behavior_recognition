{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** ——-————-————-————-————-————-————-————-————-————-————-————-————-————-————-————-————-————-————-————-—— ******************************\n",
      "轨迹条数： 34163\n",
      "---轨迹输入数据结构： torch.Size([1, 31, 44]) ---轨迹输出数据结构： torch.Size([1, 31, 4]) --行为输入数据结构\n",
      "---轨迹长度： 31 ---预测轨迹长度： 30\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from io import open\n",
    "import os.path\n",
    "from os import path\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib.ticker as ticker\n",
    "from torch import nn\n",
    "from data_prepare import *\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader, test_loader, valid_loader, WholeSet= get_dataloader(10,31,30)\n",
    "iters = iter(train_loader)\n",
    "X_train, y = next(iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        # define an RNN with specified parameters\n",
    "        # batch_first means that the first dim of the input and output will be the batch_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers,dropout=0., batch_first=True,bidirectional=False)\n",
    "        \n",
    "        # last, fully-connected layer\n",
    "        self.fc1 = nn.Linear(hidden_dim,hidden_dim*2)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_size)\n",
    "        # self.fc2 = nn.Linear(X_train.shape[2],output_size)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # get RNN outputs\n",
    "        r_out, hidden = self.lstm(x, hidden)\n",
    "        r_out = r_out.contiguous().view(-1, self.hidden_dim)  \n",
    "        \n",
    "        # get final output \n",
    "        output = self.fc1(r_out)\n",
    "        output = self.fc(output)\n",
    "        output = output.view(batch_size,-1,6) #------num\n",
    "        output = output[:,-1]\n",
    "        \n",
    "        return output\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    train_on_gpu = True\n",
    "else:\n",
    "    train_on_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_to_behavior_data(x):\n",
    "    x = x.to(device)\n",
    "    std = WholeSet.std.repeat(x.shape[0],x.shape[1],1)\n",
    "    std = std.to(device)\n",
    "    mn = WholeSet.mn.repeat(x.shape[0],x.shape[1],1)\n",
    "    mn = mn.to(device)\n",
    "    rg = WholeSet.range.repeat(x.shape[0],x.shape[1],1)\n",
    "    rg = rg.to(device)\n",
    "    input_return = (x*(rg*std)+mn).detach().cpu()\n",
    "    inputs = torch.from_numpy(input_return[:,:,:-1].detach().cpu().numpy().astype(np.float32))\n",
    "    inputs = inputs.view(-1,inputs.shape[2])\n",
    "    y = torch.from_numpy(input_return[:,:,-1].detach().cpu().numpy().astype(np.int))\n",
    "    y = y.view(-1,1).squeeze()\n",
    "    return inputs,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,epochs,train_loader,valid_loader,clip,lr = 0.0002):\n",
    "    # train for some number of epochs\n",
    "    # loss and optimization functions\n",
    "    loss_min = np.inf\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    counter = 0\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    accuracies_e = []\n",
    "    for e in range(epochs):\n",
    "        # initialize hidden state\n",
    "        net.train()\n",
    "        # batch loop\n",
    "        train_loss = []\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs,labels = trajectory_to_behavior_data(inputs)\n",
    "#             print(inputs.shape,labels.shape,labels)\n",
    "            inputs = inputs.unsqueeze(2)\n",
    "            if (train_on_gpu):\n",
    "                inputs, labels = torch.from_numpy(inputs.numpy().astype(np.float32)).to(device), labels.long().to(device)\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "            # get the output from the model\n",
    "            output = net(inputs)\n",
    "            # calculate the loss and perform backprop\n",
    "            # print(output.shape,labels.shape)\n",
    "            # print(output[:1])\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            # loss stats\n",
    "        # Get validation loss\n",
    "        val_losses = []\n",
    "        net.eval()\n",
    "        accuracies = []\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs,labels = trajectory_to_behavior_data(inputs)\n",
    "            inputs = inputs.unsqueeze(2)\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            # val_h = tuple([each.data for each in val_h])\n",
    "            if (train_on_gpu):\n",
    "                inputs, labels = torch.from_numpy(inputs.numpy().astype(np.float32)).to(device), labels.long().to(device)\n",
    "            #labels = labels.long()\n",
    "            output= net(inputs)\n",
    "            val_loss = criterion(output, labels)\n",
    "            _, class_ = torch.max(output, dim=1)\n",
    "            equal = class_ == labels.view(class_.shape)\n",
    "            accuracy = torch.mean(equal.type(torch.FloatTensor)).item()\n",
    "            val_losses.append(val_loss.item())\n",
    "            accuracies.append(accuracy)               \n",
    "        net.train()\n",
    "        losses_train.append(np.mean(train_loss))\n",
    "        losses_valid.append(np.mean(val_losses))\n",
    "        accuracies_e.append(np.mean(np.mean(accuracies)))\n",
    "        print(\"Epoch: {}/{}...\".format(e + 1, epochs),\n",
    "              \"Loss: {}...\".format(np.mean(train_loss)),\n",
    "              \"Val Loss: {}...\".format(np.mean(val_losses)),\n",
    "              \"val accuracy:{}.\".format(np.mean(accuracies))\n",
    "                     )\n",
    "        if np.mean(val_losses) < loss_min:\n",
    "            print('Val loss decreased...')\n",
    "            torch.save(net.state_dict(),'model/behavior_prediction_0707_43_30.pth')\n",
    "            loss_min = np.mean(val_losses)\n",
    "    print('min loss',loss_min)\n",
    "    plt.plot(losses_train,color='r',label='train_loss')\n",
    "    plt.plot(losses_valid,color='g',label='valid_loss')\n",
    "    plt.title('Loss_Trend')\n",
    "    plt.xlabel('Epoches')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('image/loss_lstm_behavior_0707_43_30.svg',dpi=600)\n",
    "    plt.savefig('image/loss_lstm_behavior_0707_43_30.png',dpi=600)\n",
    "    return accuracies_e\n",
    "\n",
    "def test(net,test_loader):\n",
    "    # Get test data loss and accuracy\n",
    "    lr = 0.001\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_losses = []  # track loss\n",
    "    accuracies = []\n",
    "    net.eval()\n",
    "    # iterate over test data\n",
    "    class_correct = np.zeros(6) #------num\n",
    "    class_total = np.zeros(6)\n",
    "    classes = [\"Straight\", \"LeftTurn\", \"RightTurn\", \"UTurn\", \"LeftChange\", \"RightChange\"]\n",
    "    for inputs, y in test_loader:\n",
    "        inputs,y = trajectory_to_behavior_data(inputs)\n",
    "        inputs = inputs.unsqueeze(2)\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        if (train_on_gpu):\n",
    "            inputs, y = torch.from_numpy(inputs.numpy().astype(np.float32)).to(device), y.long().to(device)\n",
    "        # get predicted outputs\n",
    "       # inputs,y = torch.from_numpy(inputs.numpy().astype(np.float32)),y.long()\n",
    "        output= net(inputs)\n",
    "        \n",
    "        # calculate loss\n",
    "        test_loss = criterion(output, y)\n",
    "        _, class_ = torch.max(output, dim=1)\n",
    "        equal = class_ == y.view(class_.shape)\n",
    "        for i in range(y.shape[0]):\n",
    "            label = y.data[i].item()\n",
    "            class_correct[label] += equal[i].item()\n",
    "            class_total[label] += 1\n",
    "        accuracy = torch.mean(equal.type(torch.FloatTensor)).item()\n",
    "        test_losses.append(test_loss.item())\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    # -- stats! -- ##\n",
    "    # avg test loss\n",
    "    print('Test Loss: {:.20f}\\n'.format(test_loss.item()))\n",
    "    for i in range(4):\n",
    "        if class_total[i]>0:\n",
    "            print('Test Accuracy of {}:{:.4f}({}/{})'.format(classes[i],100*class_correct[i]/class_total[i],\n",
    "                 int(np.sum(class_correct[i])),\n",
    "                 int(np.sum(class_total[i]))))\n",
    "        else:\n",
    "            print('Test Accuracy of {}:N/A(no examples)'.format(classes[i]))\n",
    "    print('Test Accuracy(Overall):{:.4f} ({}/{})'.format(100*np.sum(class_correct)/np.sum(class_total),\n",
    "                                                    int(np.sum(class_correct)),\n",
    "                                                    int(np.sum(class_total))))\n",
    "    print(\"Test loss: {:.10f}\".format(np.mean(test_losses)),'Test Accuracy:{}'.format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100... Loss: 0.7112118919788336... Val Loss: 0.6402720421823034... val accuracy:0.8080470499533257.\n",
      "Val loss decreased...\n",
      "Epoch: 2/100... Loss: 0.6063366368042534... Val Loss: 0.5862302641353095... val accuracy:0.8319880652748635.\n",
      "Val loss decreased...\n",
      "Epoch: 3/100... Loss: 0.48058154883366777... Val Loss: 0.4431750660159991... val accuracy:0.8687492298354242.\n",
      "Val loss decreased...\n",
      "Epoch: 4/100... Loss: 0.36616339209825804... Val Loss: 0.30380687007975804... val accuracy:0.9004219861312467.\n",
      "Val loss decreased...\n",
      "Epoch: 5/100... Loss: 0.2889292787080152... Val Loss: 0.24651579935055723... val accuracy:0.9189913774796107.\n",
      "Val loss decreased...\n",
      "Epoch: 6/100... Loss: 0.24134025409199386... Val Loss: 0.22170510366884566... val accuracy:0.9281486276038948.\n",
      "Val loss decreased...\n",
      "Epoch: 7/100... Loss: 0.20925743464411298... Val Loss: 0.17524929770265035... val accuracy:0.9404495521564389.\n",
      "Val loss decreased...\n",
      "Epoch: 8/100... Loss: 0.18664903233868135... Val Loss: 0.17398531927949093... val accuracy:0.9423282046676694.\n",
      "Val loss decreased...\n",
      "Epoch: 9/100... Loss: 0.16898320381413254... Val Loss: 0.1575497678850928... val accuracy:0.9439425238538702.\n",
      "Val loss decreased...\n",
      "Epoch: 10/100... Loss: 0.1574670444148602... Val Loss: 0.15004611155646086... val accuracy:0.950258193934979.\n",
      "Val loss decreased...\n",
      "Epoch: 11/100... Loss: 0.1480216976110079... Val Loss: 0.14888170983917157... val accuracy:0.946746341633385.\n",
      "Val loss decreased...\n",
      "Epoch: 12/100... Loss: 0.140682339867572... Val Loss: 0.1436682723711626... val accuracy:0.949295266804236.\n",
      "Val loss decreased...\n",
      "Epoch: 13/100... Loss: 0.13276303565357786... Val Loss: 0.13603878974282366... val accuracy:0.9521840487721024.\n",
      "Val loss decreased...\n",
      "Epoch: 14/100... Loss: 0.1270718766753076... Val Loss: 0.12804091856177266... val accuracy:0.9526749526439161.\n",
      "Val loss decreased...\n",
      "Epoch: 15/100... Loss: 0.12133394975477611... Val Loss: 0.11704611413219759... val accuracy:0.9560451982730935.\n",
      "Val loss decreased...\n",
      "Epoch: 16/100... Loss: 0.11703955009032384... Val Loss: 0.12066009980539984... val accuracy:0.9553371640737203.\n",
      "Epoch: 17/100... Loss: 0.11252849211935301... Val Loss: 0.10901577717793029... val accuracy:0.9586413261361523.\n",
      "Val loss decreased...\n",
      "Epoch: 18/100... Loss: 0.10781215288411823... Val Loss: 0.11457239017906412... val accuracy:0.9564133767918394.\n",
      "Epoch: 19/100... Loss: 0.10439888713114459... Val Loss: 0.11100739394021122... val accuracy:0.9593493609983809.\n",
      "Epoch: 20/100... Loss: 0.10138937090140102... Val Loss: 0.10429648670195511... val accuracy:0.9612280135532203.\n",
      "Val loss decreased...\n",
      "Epoch: 21/100... Loss: 0.09745602230306727... Val Loss: 0.08796130847422211... val accuracy:0.9658916024548427.\n",
      "Val loss decreased...\n",
      "Epoch: 22/100... Loss: 0.09375367171391125... Val Loss: 0.0877851842737745... val accuracy:0.9663069827500093.\n",
      "Val loss decreased...\n",
      "Epoch: 23/100... Loss: 0.09135393092935616... Val Loss: 0.0889241300224918... val accuracy:0.9674870409409414.\n",
      "Epoch: 24/100... Loss: 0.08688158001325028... Val Loss: 0.08511846561805554... val accuracy:0.9680062661681706.\n",
      "Val loss decreased...\n",
      "Epoch: 25/100... Loss: 0.08427181685447847... Val Loss: 0.08420890794999336... val accuracy:0.9675342435023224.\n",
      "Val loss decreased...\n",
      "Epoch: 26/100... Loss: 0.07986032690536225... Val Loss: 0.07165786522830575... val accuracy:0.9718107734031415.\n",
      "Val loss decreased...\n",
      "Epoch: 27/100... Loss: 0.07670255425701068... Val Loss: 0.07864028639613528... val accuracy:0.9711877028252041.\n",
      "Epoch: 28/100... Loss: 0.0744825062775491... Val Loss: 0.07495776804612238... val accuracy:0.9730474743397919.\n",
      "Epoch: 29/100... Loss: 0.07124937466853817... Val Loss: 0.07548611743395175... val accuracy:0.9721128680934884.\n",
      "Epoch: 30/100... Loss: 0.06781663325988879... Val Loss: 0.07063525428758011... val accuracy:0.9747939599006888.\n",
      "Val loss decreased...\n",
      "Epoch: 31/100... Loss: 0.06525770138062947... Val Loss: 0.06231544008933455... val accuracy:0.975322625443082.\n",
      "Val loss decreased...\n",
      "Epoch: 32/100... Loss: 0.06371615733792477... Val Loss: 0.050947529766251935... val accuracy:0.9796935604841066.\n",
      "Val loss decreased...\n",
      "Epoch: 33/100... Loss: 0.06033342934405573... Val Loss: 0.06250342528201239... val accuracy:0.9763799574087683.\n",
      "Epoch: 34/100... Loss: 0.05955688613848833... Val Loss: 0.06071024064719237... val accuracy:0.9766631715996139.\n",
      "Epoch: 35/100... Loss: 0.05596607065994654... Val Loss: 0.0533259807842827... val accuracy:0.9792498588771335.\n",
      "Epoch: 36/100... Loss: 0.05391115609531729... Val Loss: 0.05443279679975255... val accuracy:0.9800145367816209.\n",
      "Epoch: 37/100... Loss: 0.05261791698854416... Val Loss: 0.04706195132053969... val accuracy:0.98102466571495.\n",
      "Val loss decreased...\n",
      "Epoch: 38/100... Loss: 0.05095258990959526... Val Loss: 0.04693263579162681... val accuracy:0.9823935334623854.\n",
      "Val loss decreased...\n",
      "Epoch: 39/100... Loss: 0.0484511656219719... Val Loss: 0.04838273763843723... val accuracy:0.9813645229131672.\n",
      "Epoch: 40/100... Loss: 0.04769765389988869... Val Loss: 0.0626691874865286... val accuracy:0.9785323838392893.\n",
      "Epoch: 41/100... Loss: 0.04653381954530232... Val Loss: 0.04333319025414218... val accuracy:0.9848858156433083.\n",
      "Val loss decreased...\n",
      "Epoch: 42/100... Loss: 0.04410016318759128... Val Loss: 0.05426849105367565... val accuracy:0.9801467028423329.\n",
      "Epoch: 43/100... Loss: 0.043390039048167205... Val Loss: 0.044966412147104326... val accuracy:0.9831393298294797.\n",
      "Epoch: 44/100... Loss: 0.0421964967201426... Val Loss: 0.043414825052815506... val accuracy:0.984697006958983.\n",
      "Epoch: 45/100... Loss: 0.04091935077170555... Val Loss: 0.03638806640917415... val accuracy:0.9860847551361455.\n",
      "Val loss decreased...\n",
      "Epoch: 46/100... Loss: 0.03847154274464846... Val Loss: 0.05072163765635606... val accuracy:0.9831298897672474.\n",
      "Epoch: 47/100... Loss: 0.03771789399207212... Val Loss: 0.04133309723875163... val accuracy:0.9852634346429319.\n",
      "Epoch: 48/100... Loss: 0.03595900738082773... Val Loss: 0.044877593105645736... val accuracy:0.9846592451226897.\n",
      "Epoch: 49/100... Loss: 0.03697510764402651... Val Loss: 0.037526770050769424... val accuracy:0.9851595893707197.\n",
      "Epoch: 50/100... Loss: 0.03515026143027669... Val Loss: 0.03167480180820647... val accuracy:0.9881144547570614.\n",
      "Val loss decreased...\n",
      "Epoch: 51/100... Loss: 0.03441797769277323... Val Loss: 0.03492563789386379... val accuracy:0.9865756589032978.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7a24a9c2b825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training time is:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-82dfe1fc72fc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, epochs, train_loader, valid_loader, clip, lr)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrajectory_to_behavior_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#             print(inputs.shape,labels.shape,labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-041db5fef10f>\u001b[0m in \u001b[0;36mtrajectory_to_behavior_data\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0minput_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrg\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_return\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_return\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = LSTM(1,6,256,2) #------num\n",
    "from time import time\n",
    "if train_on_gpu:\n",
    "    net.to(device)\n",
    "start = time()\n",
    "epochs = 100\n",
    "accuracy = train(net,epochs,train_loader,valid_loader,clip=5,lr=0.0001)\n",
    "print('Training time is:',time()-start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracy,color='b',label='accuracy')\n",
    "plt.title('Accuracy_Trend')\n",
    "plt.xlabel('Epoches')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('image/accuracy_lstm_behavior_25.svg',dpi=300)\n",
    "plt.savefig('image/accuracy_lstm_behavior_25.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_test = LSTM(1,6,256,2) #------num\n",
    "net_test.load_state_dict(torch.load('model/behavior_prediction_0707_43_30.pth',map_location='cuda'))\n",
    "if train_on_gpu:\n",
    "    net_test.cuda()   \n",
    "test(net_test,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 37.323713302612305 ms\n",
      "tensor([[  9.8558,   6.5670, -11.7465, -14.8528]], grad_fn=<SelectBackward>)\n",
      "tensor([[  9.8558,   6.5670, -11.7465, -14.8528]], grad_fn=<SelectBackward>)\n",
      "tensor([[  6.2286,   3.8929,  -5.5848, -13.0892]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "net_test.cpu().eval()\n",
    "from time import time\n",
    "# An example input you would normally provide to your model's forward() method.\n",
    "#example = torch.rand(1, 4)\n",
    "\n",
    "example = torch.ones(1,43,1).cuda()\n",
    "t = time()\n",
    "out = net_test(example)\n",
    "print('time',(time()-t)*1000,'ms')\n",
    "print(out)\n",
    "# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
    "traced_script_module = torch.jit.trace(net_test, example)\n",
    "traced_script_module.save(\"model/behavior_prediction_LSTM_0707_31_30_cuda.pt\")\n",
    "example1 = torch.zeros(1,43,1).cpu()\n",
    "out= traced_script_module(example)\n",
    "out1 = traced_script_module(example1)\n",
    "print(out)\n",
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
